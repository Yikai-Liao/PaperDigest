# é¢„æµ‹ç®¡é“è°ƒè¯•ä¿®å¤æŠ¥å‘Š

## ğŸ“‹ é—®é¢˜æ¦‚è¿°

GitHub Actions å·¥ä½œæµåœ¨è¿è¡Œ `fit_predict.py` æ—¶é‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

1. **FileNotFoundError**: `/home/runner/work/PaperDigest/PaperDigest/data/predictions.parquet` ç›®å½•ä¸å­˜åœ¨
2. **ValueError**: Input X contains NaN - sklearn çš„ `NearestNeighbors` å’Œ `LogisticRegression` ä¸æ¥å—åŒ…å« NaN çš„æ•°æ®

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### 1. ç›®å½•ä¸å­˜åœ¨é—®é¢˜
```python
output_file = REPO_ROOT / "data" / "predictions.parquet"
results_df.write_parquet(output_file)  # âŒ å¦‚æœ data/ ç›®å½•ä¸å­˜åœ¨ä¼šå¤±è´¥
```

**åŸå› **: é¡¹ç›®é‡ç»„åå°† `predictions.parquet` ç§»åˆ°äº† `data/` ç›®å½•ï¼Œä½†ä»£ç æ²¡æœ‰ç¡®ä¿ç›®å½•å­˜åœ¨ã€‚

### 2. NaN å€¼é—®é¢˜

é”™è¯¯å‘ç”Ÿåœ¨ä¸¤ä¸ªåœ°æ–¹ï¼š

#### a) è‡ªé€‚åº”éš¾åº¦é‡‡æ ·å‡½æ•°
```python
# adaptive_difficulty_sampling()
nn_background.fit(unlabeled_data)  # âŒ unlabeled_data åŒ…å« NaN
```

#### b) é¢„æµ‹é˜¶æ®µ
```python
# predict_and_recommend()
target_scores = model.predict_proba(X_target)[:, 1]  # âŒ X_target åŒ…å« NaN
```

**åŸå› **: Hugging Face æ•°æ®é›†ä¸­çš„ embedding æ•°æ®å¯èƒ½åŒ…å« NaN å€¼ï¼ˆç¼ºå¤±çš„åµŒå…¥ï¼‰ã€‚sklearn çš„ç®—æ³•é»˜è®¤ä¸å¤„ç† NaNã€‚

## âœ… ä¿®å¤æ–¹æ¡ˆ

### 1. ç¡®ä¿ç›®å½•å­˜åœ¨

åœ¨ `predict_and_save()` å‡½æ•°ä¸­ä¿å­˜æ–‡ä»¶å‰åˆ›å»ºç›®å½•ï¼š

```python
output_file = REPO_ROOT / "data" / "predictions.parquet"

# ç¡®ä¿ç›®å½•å­˜åœ¨
output_file.parent.mkdir(parents=True, exist_ok=True)

# ä¿å­˜
results_df.write_parquet(output_file)
```

### 2. å¤„ç† NaN å€¼

#### a) åœ¨è‡ªé€‚åº”éš¾åº¦é‡‡æ ·å‡½æ•°ä¸­
```python
# adaptive_difficulty_sampling()
try:
    # æ£€æŸ¥å¹¶å¤„ç† NaN å€¼
    if np.isnan(x_pos).any():
        logger.warning(f"æ­£æ ·æœ¬æ•°æ®ä¸­å‘ç° NaN å€¼ï¼Œå°†æ›¿æ¢ä¸º 0")
        x_pos = np.nan_to_num(x_pos, nan=0.0)
    
    if np.isnan(unlabeled_data).any():
        logger.warning(f"èƒŒæ™¯æ•°æ®ä¸­å‘ç° NaN å€¼ï¼Œå°†æ›¿æ¢ä¸º 0")
        unlabeled_data = np.nan_to_num(unlabeled_data, nan=0.0)
    
    # 1. å¯¹èƒŒæ™¯æ•°æ®å»ºç«‹KNNæ¨¡å‹
    nn_background = NearestNeighbors(...)
    nn_background.fit(unlabeled_data)  # âœ… ç°åœ¨æ•°æ®å·²æ¸…ç†
```

#### b) åœ¨é¢„æµ‹å‡½æ•°ä¸­
```python
# predict_and_recommend()
X_target = np.hstack([np.vstack(target_df[col].to_numpy()) for col in embedding_columns])

# å¤„ç† NaN å€¼
nan_count = np.isnan(X_target).sum()
if nan_count > 0:
    logger.warning(f"é¢„æµ‹æ•°æ®ä¸­å‘ç° {nan_count} ä¸ª NaN å€¼ï¼Œå°†æ›¿æ¢ä¸º 0")
    X_target = np.nan_to_num(X_target, nan=0.0)

# ä½¿ç”¨æ¨¡å‹é¢„æµ‹"å–œæ¬¢"çš„æ¦‚ç‡
target_scores = model.predict_proba(X_target)[:, 1]  # âœ… æ•°æ®å·²æ¸…ç†
```

## ğŸ§ª æœ¬åœ°æµ‹è¯•ç»“æœ

è¿è¡Œ `uv run python script/fit_predict.py` æˆåŠŸæ‰§è¡Œï¼š

```
2025-10-01 15:26:38.669 | WARNING  | __main__:adaptive_difficulty_sampling:238 - èƒŒæ™¯æ•°æ®ä¸­å‘ç° NaN å€¼ï¼Œå°†æ›¿æ¢ä¸º 0
2025-10-01 15:26:45.121 | WARNING  | __main__:predict_and_recommend:514 - é¢„æµ‹æ•°æ®ä¸­å‘ç° 3371008 ä¸ª NaN å€¼ï¼Œå°†æ›¿æ¢ä¸º 0
2025-10-01 15:26:45.178 | INFO     | __main__:predict_and_recommend:520 - é¢„æµ‹å®Œæˆï¼Œåˆ†æ•°èŒƒå›´: 0.0305 - 0.6341, å¹³å‡: 0.2218
2025-10-01 15:26:45.211 | INFO     | __main__:predict_and_save:711 - é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: /home/lyk/code/PaperDigest/data/predictions.parquet
2025-10-01 15:26:45.212 | INFO     | __main__:predict_and_save:715 - æ¨è13ç¯‡è®ºæ–‡
```

âœ… **æˆåŠŸ**:
- è®­ç»ƒå®Œæˆï¼ˆ169 æ­£æ ·æœ¬ + 845 è´Ÿæ ·æœ¬ = 1077 æ€»æ ·æœ¬ï¼‰
- è‡ªé€‚åº”éš¾åº¦é‡‡æ ·æˆåŠŸï¼ˆ338 æ ·æœ¬ = 169 é‡é‡‡æ · + 169 SMOTE åˆæˆï¼‰
- é¢„æµ‹å®Œæˆï¼ˆ3292 ç¯‡è®ºæ–‡ï¼Œæ¨è 13 ç¯‡ï¼‰
- æ–‡ä»¶æˆåŠŸä¿å­˜åˆ° `data/predictions.parquet` (1.7MB)

## ğŸ“Š NaN å€¼ç»Ÿè®¡

### è®­ç»ƒé˜¶æ®µ
- **152ä¸ªæ ·æœ¬ (14.11%)** åŒ…å«NaNå€¼ â†’ å·²æ›¿æ¢ä¸º0

### é‡‡æ ·é˜¶æ®µ  
- **èƒŒæ™¯æ•°æ®**ä¸­å‘ç° NaN å€¼ â†’ å·²æ›¿æ¢ä¸º0

### é¢„æµ‹é˜¶æ®µ
- **3,371,008 ä¸ª NaN å€¼**ï¼ˆåœ¨ 3292 ç¯‡è®ºæ–‡ Ã— 2816 ç»´ç‰¹å¾ä¸­ï¼‰â†’ å·²æ›¿æ¢ä¸º0
- çº¦ **36%** çš„ç‰¹å¾å€¼ä¸º NaN

## ğŸ’¡ NaN å€¼æ¥æºåˆ†æ

NaN å€¼ä¸»è¦æ¥è‡ªï¼š
1. **åµŒå…¥ç¼ºå¤±**: æŸäº›è®ºæ–‡å¯èƒ½æ²¡æœ‰å®Œæ•´çš„åµŒå…¥å‘é‡
2. **æ•°æ®ç‰ˆæœ¬å·®å¼‚**: ä¸åŒå¹´ä»½çš„æ•°æ®å¯èƒ½åŒ…å«ä¸åŒçš„åµŒå…¥åˆ—
3. **Polars scan_parquet**: ä½¿ç”¨ `allow_missing_columns=True` å‚æ•°ï¼Œç¼ºå¤±åˆ—ä¼šè¢«å¡«å……ä¸º null

## ğŸ”§ æ›¿ä»£æ–¹æ¡ˆï¼ˆæœªé‡‡ç”¨ï¼‰

è€ƒè™‘è¿‡ä½†æœªé‡‡ç”¨çš„æ–¹æ¡ˆï¼š

### 1. åˆ é™¤åŒ…å« NaN çš„æ ·æœ¬
```python
# âŒ ä¸æ¨èï¼šä¼šæŸå¤±å¤§é‡æ•°æ®
mask = ~np.isnan(X).any(axis=1)
X = X[mask]
y = y[mask]
```
**ç¼ºç‚¹**: ä¼šä¸¢å¤± 14-36% çš„æ•°æ®

### 2. ä½¿ç”¨æ›´å¤æ‚çš„å¡«å……ç­–ç•¥
```python
# âŒ å¯èƒ½è¿‡åº¦å¤æ‚
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)
X = imputer.fit_transform(X)
```
**ç¼ºç‚¹**: è®¡ç®—æˆæœ¬é«˜ï¼Œå¯èƒ½å¼•å…¥åå·®

### 3. ä½¿ç”¨æ”¯æŒ NaN çš„æ¨¡å‹
```python
# âŒ éœ€è¦é‡æ„å¤§é‡ä»£ç 
from sklearn.ensemble import HistGradientBoostingClassifier
model = HistGradientBoostingClassifier()
```
**ç¼ºç‚¹**: éœ€è¦æ”¹å˜æ¨¡å‹æ¶æ„å’Œè¶…å‚æ•°

## âœ¨ é€‰æ‹©ç®€å•å¡«å……ï¼ˆ0ï¼‰çš„ç†ç”±

1. **ç®€å•é«˜æ•ˆ**: ä¸å¢åŠ è®¡ç®—æˆæœ¬
2. **ä¿ç•™æ‰€æœ‰æ ·æœ¬**: ä¸ä¸¢å¤±æ•°æ®
3. **åˆç†å‡è®¾**: ç¼ºå¤±çš„åµŒå…¥ç»´åº¦å€¼ä¸º 0 å¯è§£é‡Šä¸º"è¯¥ç»´åº¦æ— ä¿¡æ¯"
4. **ä¸€è‡´æ€§**: ä¸è®­ç»ƒå’Œé¢„æµ‹é˜¶æ®µä¿æŒä¸€è‡´çš„å¤„ç†æ–¹å¼

## ğŸ“ åç»­å»ºè®®

### çŸ­æœŸ
- âœ… ç›‘æ§ GitHub Actions è¿è¡Œï¼Œç¡®è®¤ä¿®å¤æœ‰æ•ˆ
- âš ï¸ å…³æ³¨æ—¥å¿—ä¸­çš„ NaN è­¦å‘Šï¼Œäº†è§£æ•°æ®è´¨é‡

### é•¿æœŸ
- ğŸ” è°ƒæŸ¥ Hugging Face æ•°æ®é›†ä¸­ NaN çš„æ¥æº
- ğŸ“Š è€ƒè™‘æ›´æ–°åµŒå…¥æ•°æ®é›†ï¼Œå‡å°‘ç¼ºå¤±å€¼
- ğŸ§ª è¯„ä¼°ä¸åŒå¡«å……ç­–ç•¥å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“
- ğŸ“ˆ æ·»åŠ æ•°æ®è´¨é‡æŒ‡æ ‡åˆ°æ—¥å¿—ä¸­

## ğŸ¯ æäº¤ä¿¡æ¯

```
fix: handle NaN values in prediction pipeline and ensure data directory exists

- Add NaN value handling before prediction to avoid sklearn errors
- Add NaN value handling in adaptive_difficulty_sampling function
- Ensure data/ directory exists before saving predictions.parquet
- Fixes FileNotFoundError and ValueError related to NaN values
```

**Commit**: `c90f351`
**ä¿®æ”¹æ–‡ä»¶**: `script/fit_predict.py` (+18 è¡Œ)
