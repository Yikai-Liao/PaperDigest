---
title: "Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision"
slug: "2504.21423"
description: "本文提出Diff-Prompt方法，使用扩散模型基于掩码监督生成细粒度提示信息，显著提升预训练多模态模型在复杂指代表达理解任务上的性能，同时保持高效微调。"
tags: ["Diffusion Model", "Prompt Learning", "Multimodal", "Fine-Tuning", "Mask Supervision"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:32:03.586802+00:00
preference: "unknown"
score: 0.5438955499904097
featured: false
draft: false
---

> 本文提出Diff-Prompt方法，使用扩散模型基于掩码监督生成细粒度提示信息，显著提升预训练多模态模型在复杂指代表达理解任务上的性能，同时保持高效微调。

> Diffusion Model, Prompt Learning, Multimodal, Fine-Tuning, Mask Supervision 

> Weicai Yan, Wang Lin, Zirun Guo, Ye Wang, Fangming Feng, Xiaoda Yang, Zehan Wang, Tao Jin

> Zhejiang University 

## Background Problem

提示学习在微调预训练多模态模型时显示出有前景的结果，但应用于更复杂和细粒度的任务时，性能提升有限。原因是现有方法通过损失反向传播直接优化提示生成过程中的参数，这限制了提示表示的丰富性和特异性。具体来说，现有的提示学习方法存在两个主要问题：一是不同模态的提示独立学习，无法建立模态间连接；二是只能学习全局提示，无法针对特定输入生成细粒度提示。这些问题在处理需要考虑模态间复杂关系的任务时（如指代表达理解）会导致性能提升有限，甚至不如基础模型。

## Method

*   **核心思想：** 本文提出Diff-Prompt方法，使用扩散模型生成丰富且细粒度的提示信息，以提升预训练多模态模型在复杂下游任务上的性能。具体目标是通过掩码监督，生成能强调图像中特定部分的提示，帮助模型更好地融合多模态信息。
*   **实现步骤：** 该方法分为三个阶段：
    1. **Mask-VAE训练阶段：** 训练一个Mask-VAE模型，将掩码压缩到潜空间中，减少计算复杂度。给定掩码$m \in \mathbb{R}^{1\times H\times W}$，编码器$\mathcal{E}$输出均值和方差向量，采样潜变量$z \sim \mathcal{N}(\mu, \sigma^2)$，解码器$\mathcal{D}$重建掩码$\tilde{m}$。损失函数为$\mathcal{L}_{\text{vae}} = \|m - \tilde{m}\|_2^2 + \lambda D_{\text{KL}}(\mathcal{N}(\mu, \sigma^2) \|\| \mathcal{N}(0, \mathbf{I}))$。
    2. **提示生成阶段：** 使用改进的Diffusion Transformer (DiT)模型在潜空间中训练提示生成器$\epsilon^\theta$，以掩码为监督，条件为图像和标题。扩散过程通过添加噪声得到$z_t$，训练损失为$\mathcal{L}_{\theta} = \|\epsilon_{\theta}(z_t, C) - \epsilon_t\|_2^2$，其中$C$包括图像嵌入、标题嵌入和时间步嵌入。采样使用DDIM加速，保留中间潜变量作为提示。
    3. **提示微调阶段：** 冻结前两阶段模型，使用模态特定适配器(Adapter$^v$和Adapter$^l$)将生成提示语义对齐到预训练模型空间，并与少量可学习全局提示连接，输入到编码器中进行微调。最终输出通过下游头预测目标位置。

## Experiment

*   **数据集和评估指标：** 本文在指代表达理解任务上进行实验，使用RefCOCO和Flickr30k数据集。评估指标包括Recall at K (R@K，表示模型在top K检索结果中正确识别目标的比例)和Upper Bound (UB，表示目标在所有预测结果中的比例)。具体选择了R@1、R@5和UB作为标准。
*   **实验设置：** 以GLIP-T(A)作为基础模型，与多种参数高效微调方法（如适配器方法：Tip-adapter、CLIP-Adapter、Meta-adapter、MMA；提示调优方法：VPT、VFPT、CoOp、S-Prompts、MaPLe、FedTPG）进行比较。实验细节包括：Mask-VAE训练200个epoch，批量大小128，学习率0.05；提示生成器使用DDIM采样，Tsample=25；微调阶段学习率0.0001，使用AdamW优化器。删繁就简地控制了提示深度和长度，以平衡性能和计算开销。
*   **结果分析：** Diff-Prompt在RefCOCO数据集上显著优于基线方法，例如在testA子集上R@1提升8.87%、R@5提升14.05%。在Flickr30k上也表现出色。结果符合预期，因为扩散模型生成的提示提供了输入特定的丰富信息，提升了模态融合。定性分析显示Diff-Prompt在位置敏感性、语言理解和物体识别上更强。消融实验证实了提示组件的有效性，提示深度增加时性能稳健提升。实验设置合理全面，涵盖了定量、定性、消融和泛化分析，验证了方法的鲁棒性和泛化能力。

## Further Thoughts 

这项工作启发了使用生成模型增强提示学习的潜力，例如可以将扩散模型扩展到其他模态融合任务中，或结合控制Net-like方法实现更精确的条件生成；此外，提示生成器的多步退化过程可能启发更高效的一步生成模型，以减少计算开销；同时，与其他扩散模型相关研究（如DreamBooth）结合，可能提升零样本泛化能力，但需注意潜在过拟合风险和计算资源限制。