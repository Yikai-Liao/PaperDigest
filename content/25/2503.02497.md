---
title: "PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset"
slug: "2503.02497"
description: "本文提出 PennyLang 数据集和 RAG/GraphRAG 框架，通过提升 LLM 在 PennyLane 量子代码生成中的准确性和正确性，填补了 AI 辅助量子编程的空白。"
tags: ["Quantum Computing", "Large Language Models", "PennyLane", "RAG", "GraphRAG", "Code Generation", "Dataset Curation"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:26:48.387862+00:00
preference: "unknown"
score: 0.5537193384825627
featured: false
draft: false
---

> 本文提出 PennyLang 数据集和 RAG/GraphRAG 框架，通过提升 LLM 在 PennyLane 量子代码生成中的准确性和正确性，填补了 AI 辅助量子编程的空白。

> Quantum Computing, Large Language Models, PennyLane, RAG, GraphRAG, Code Generation, Dataset Curation 

> Abdul Basit, Nouhaila Innan, Haider Asif, Minghao Shao, Muhammad Kashif, Alberto Marchisio, Muhammad Shafique

> New York University Abu Dhabi 

## Background Problem

量子计算作为一项变革性技术，具有解决经典系统无法处理的复杂问题的潜力，但现有框架的专业性导致编程挑战，阻碍了其广泛采用。PennyLane 是一个领先的开源 Python 框架，专注于混合量子-经典计算，但与 Qiskit 框架相比，缺乏等效的 AI 驱动代码辅助工具。大型语言模型 (LLMs) 在经典编程中表现出色，能够提高开发效率并减少错误，但其在量子编程，尤其是 PennyLane 生态系统中的应用仍未得到充分探索。本文从解决 PennyLane 缺乏高质量数据集和 AI 辅助工具的空白入手，针对量子代码生成中的数据可用性和上下文关联问题，构建了一个专为 PennyLane 设计的指令-响应数据集，并开发了评估框架，以提升 LLM 在量子编程任务中的性能。

## Method

* **核心思想:** 本文的核心是构建一个名为 PennyLang 的高质量数据集，并使用检索增强生成 (RAG) 和 GraphRAG 框架来提升 LLM 在 PennyLane 量子代码生成中的性能，强调通过外部上下文检索来减少幻觉和提高代码正确性。
* **如何实现:** 方法包括三个主要部分：(1) 数据收集和精炼：从 GitHub 仓库、量子计算书籍（如 'Quantum Machine Learning: An Applied Approach' 和 'A Practical Guide to Quantum Machine Learning and Quantum Optimization'）以及官方 PennyLane 文档中提取 3,347 个 PennyLane 特定代码样本，并通过手动审查和使用 GPT-4o API 转换为指令-响应对；(2) 数据预处理：包括标记化、填充策略（如左填充）和注意力掩码，以适应 transformer 模型的输入要求；(3) RAG 和 GraphRAG 管道：使用 LangChain 和 Chroma 数据库实现基线 RAG，通过最大边际相关性 (MMR) 检索相关上下文；GraphRAG 进一步通过构建代码样本的图结构（节点为代码样本，边为功能或结构相似性）来改进检索精度，实现更准确的上下文关联。
* **主要步骤:** (1) 系统数据收集，确保多样性和完整性；(2) 数据标注和格式化；(3) 实现 RAG/GraphRAG 框架，与 LLM 集成；(4) 通过查询处理动态生成代码。

## Experiment

* **实验设置:** 本文使用 PennyLang 数据集（包含 3,347 个样本）和 QHack 挑战数据集（29 个任务）进行评估。实验比较了三种 LLM（GPT-4o Mini、Claude 3.5 Sonnet 和 Qwen 2.5-7B-Instruct-Turbo）在无 RAG、基线 RAG 和 GraphRAG 条件下的性能。指标包括功能性（代码是否产生正确量子行为）、语法正确性（代码是否可执行）和模块性（代码是否组织良好、可重用）。GraphRAG 实验使用 146 个 PennyLang 测试任务，评估正确性通过单元测试确定。
* **数据集和原因:** PennyLang 数据集从多个来源收集，确保覆盖量子门、测量和优化等多样场景；QHack 用于实际任务模拟。实验设计合理，考虑了不同模型和检索方法的比较，以验证 RAG/GraphRAG 的泛化能力。
* **结果:** RAG 显著提升性能，例如 GPT-4o Mini 的准确性和模块性平均提高 11.67%，Claude 3.5 提高 7.69%，Qwen 2.5 提高 14.38%。GraphRAG 进一步将 GPT-4o Mini 的准确率从 20.5% 提升到 58.2%，绝对改善 37.7%。案例研究显示 RAG 优化代码在功能性和模块性上表现更好（如参数绑定和硬件优化）。结果符合预期，证明了数据集和方法的有效性，实验设置全面，涵盖定量指标和定性分析。

## Further Thoughts 

这项工作强调了高质量数据集在专业领域 AI 应用中的关键作用，未来可探索将 GraphRAG 扩展到其他量子框架如 Qiskit 或 Cirq，以实现跨框架代码生成；此外，结合量子机器学习中的噪声中间规模量子 (NISQ) 设备优化或与其他 AI 技术（如强化学习）整合，可能进一步提升模型鲁棒性和泛化能力，并为量子计算在实际应用中的部署提供更深层的洞见。