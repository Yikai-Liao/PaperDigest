---
title: "Honey, I Shrunk the Language Model: Impact of Knowledge Distillation Methods on Performance and Explainability"
slug: "2504.16056"
description: "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u6279\u8bc4-\u4fee\u8ba2\u63d0\u793a\u548c\u6bd4\u8f83\u591a\u4efb\u52a1\u8bad\u7ec3\u3001\u53cd\u4e8b\u5b9e\u8bad\u7ec3\u53ca\u5176\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u77e5\u8bc6\u84b8\u998f\u5bf9\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u591a\u4efb\u52a1\u8bad\u7ec3\u5728\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u800c\u7ed3\u5408\u6279\u8bc4-\u4fee\u8ba2\u63d0\u793a\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u53ef\u89e3\u91ca\u6027\u3002"
tags: ["Explainability", "Language Model", "Knowledge Distillation", "Multitask Training", "Counterfactual Training"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:29:44.925671+00:00
preference: "like"
score: 0.8290656420598665
featured: false
draft: false
---

> 本文通过引入批评-修订提示和比较多任务训练、反事实训练及其结合的方法，系统评估了知识蒸馏对语言模型性能和可解释性的影响，发现多任务训练在性能上表现出色，而结合批评-修订提示的方法显著提升了可解释性。

> Explainability, Language Model, Knowledge Distillation, Multitask Training, Counterfactual Training 

> Daniel Hendriks, Philipp Spitzer, Niklas Kühl, Gerhard Satzger

> Karlsruhe Institute of Technology, University of Bayreuth 

## Background Problem

人工智能（AI）在现代社会中扮演着重要角色，特别是大型语言模型（LLMs）的快速发展推动了自然语言处理（NLP）领域的进步。然而，LLMs 的高计算和存储需求限制了其在资源受限环境（如移动设备和边缘设备）中的部署。知识蒸馏是一种通过从大型教师模型向小型学生模型转移知识的方法，以维持性能的同时提高部署便利性、能效和推理速度。但现有研究尚未系统比较不同蒸馏方法对模型性能和可解释性的影响。本文针对两个研究问题：（1）批评-修订提示如何影响数据质量，从而影响学生模型的性能和可解释性；（2）当前训练方法如何影响学生模型的性能和可解释性。背景包括LLMs的有效性依赖于其规模，但规模带来的挑战促使知识蒸馏的发展，同时强调了可解释性的重要性，以确保人类理解和信任模型输出。

## Method

本文的方法包括数据生成和学生模型训练两个方面。核心思想是通过改进训练数据和训练策略来优化知识蒸馏过程，以平衡性能和可解释性。具体实现：
- **数据生成：** 引入批评-修订提示（critique-revision prompting），基于教师模型生成初始解释，然后通过批评和修订步骤改进解释。形式化定义为数据集 $\mathcal{D} = \{ (q_i, a_i, e_i, c_i, e'_i) \}_{i=1}^N$，其中 $q_i$ 是问题，$a_i$ 是正确答案，$e_i$ 是初始解释，$c_i$ 是批评，$e'_i$ 是修订后解释。生成过程包括三个步骤：（1）教师模型生成初始解释 $e_i = \text{TeacherModel}(q_i, a_i, \text{"Explain"})$；（2）生成批评 $c_i = \text{TeacherModel}(q_i, a_i, e_i, \text{"Critique"})$；（3）生成修订解释 $e'_i = \text{TeacherModel}(q_i, a_i, e_i, c_i, \text{"Revis"})$。
- **学生模型训练：** 比较多任务训练（multitask training）、反事实训练（counterfactual training）和二者结合。损失函数定义为：多任务训练的 $\mathcal{L}_{\text{multitask}} = \mathcal{L}_{\text{answer}} + \mathcal{L}_{\text{explination}}$，其中 $\mathcal{L}_{\text{answer}} = \frac{1}{N} \sum_{i=1}^{N} l(f(q_i), a_i)$ 和 $\mathcal{L}_{\text{explination}} = \frac{1}{N} \sum_{i=1}^{N} l(f(q_i), e_i)$；反事实训练的 $\mathcal{L}_{\text{counterfrac}} = \mathcal{L}_{\text{correct}} + \mathcal{L}_{\text{incorrect}}$，其中 $\mathcal{L}_{\text{correct}} = \frac{1}{N} \sum_{i=1}^{N} l(f(q_i), a_i)$ 和 $\mathcal{L}_{\text{incorrect}} = \frac{1}{N} \sum_{i=1}^{N} l(f(q_i, e_i^*), a_i^*)$，$e_i^*$ 是基于错误答案生成的反事实解释；结合训练的 $\mathcal{L}_{\text{combined}} = \mathcal{L}_{\text{multitask}} + \mathcal{L}_{\text{counterfactorial}}$。这些方法通过提示和损失函数优化学生模型的学习过程。

## Experiment

实验使用Commonsense Question-Answering (CQA)数据集，共9741个训练样本和1221个测试样本。教师模型为LLaMA-2-13B（使用未对齐和聊天调整版本），学生模型为T5-base（220M参数）和T5-large（770M参数）。性能评估通过准确率衡量，实验设置包括固定随机种子、使用AdamW优化器、学习率为5×10^{-5}，训练步数为5000步。解释性通过一项人类参与研究评估，招募117名参与者（通过Prolific平台），每个参与者评估12个解释（每个学生模型3个），沿五个维度（plausibility、understandability、completeness、satisfaction、contrastiveness）使用五点Likert量表评分，总计7020个评估。结果显示：多任务训练在性能上表现出色，准确率最高；批评-修订提示未改善性能，但显著提升了解释性的完整性和对比性（如MT+CF:Revised模型在对比性和完整性上优于其他模型）。实验设置合理全面，人类研究确保了解释性的真实性，ANOVA和Kruskal-Wallis测试证实了显著差异，回归分析显示批评-修订提示对解释质量有正向影响，结果部分符合预期（性能上多任务训练优异，解释性上结合方法提升明显），但批评-修订提示对性能的负面影响出人意料，可能由于解释冗长导致模型混淆。

## Further Thoughts 

这项工作突显了在知识蒸馏中兼顾性能和可解释性的重要性，启发我们思考如何将批评-修订提示扩展到其他AI任务中，例如结合强化学习来动态优化解释生成，或应用于医疗AI以提升模型的可信度；此外，与其他研究如Orca或PaLM的比较表明，教师模型规模并非决定性因素，未来可探索跨领域数据集的泛化能力，以推动更高效且可解释的AI系统发展。