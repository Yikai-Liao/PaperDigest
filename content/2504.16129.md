---
title: "MARFT: Multi-Agent Reinforcement Fine-Tuning"
slug: "2504.16129"
description: "本文提出MARFT框架，通过序列决策和信任区域优化在LLM-based多代理系统中实现高效强化微调，提升代理协作能力并解决传统MARL的适用性问题。"
tags: ["Multi-Agent Systems", "Reinforcement Learning", "Fine-Tuning", "Large Language Models", "Agent Collaboration"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:28:41.233523+00:00
preference: "unknown"
score: 0.5639480740259718
featured: false
draft: false
---

> 本文提出MARFT框架，通过序列决策和信任区域优化在LLM-based多代理系统中实现高效强化微调，提升代理协作能力并解决传统MARL的适用性问题。

> Multi-Agent Systems, Reinforcement Learning, Fine-Tuning, Large Language Models, Agent Collaboration 

> Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

> Shanghai Jiao Tong University, Shanghai Innovation Institute, Xi'an Jiaotong University, OPPO Research Institute 

## Background Problem

本研究源于大型语言模型（LLM）在复杂代理任务中的强大表现，但现有研究对基于LLM的多代理系统（LaMAS）使用强化学习（RL）进行微调的探索有限。直接应用传统多代理强化学习（MARL）方法到LaMAS中面临诸多挑战，包括异步代理交互、代理配置文件设计、异构架构等，这些问题源于LaMAS的独特特性。研究背景强调了从传统RL到强化微调（RFT）的演变，以及LaMAS在处理复杂任务中的优势，但也指出传统MARL方法在LaMAS中的适用性不足，需要一个针对LaMAS的通用框架来提升代理系统的智能性和协作能力。

## Method

*   **核心思想：** MARFT 提出一个针对LLM-based多代理系统的强化微调框架，基于Flexible Partially Observable Markov Decision Process（Flex-POMDP）模型，引入依赖函数D来处理异步和动态代理交互。核心是通过序列决策建模和信任区域优化（如PPO）来微调代理策略，确保单代理和系统整体性能的单调改进。
*   **工作原理：** 在行动级别，MARFT使用序列建模将多代理决策转化为顺序决策过程，每个代理基于前置代理的行动和滚动观察生成行动。信任区域方法（如PPO）通过最小化KL散度确保策略更新稳定。行动归一化处理行动长度差异，代理逐个更新减少脱策略问题。token级别微调进一步细化信用分配，将每个token视为行动，计算token级Q函数和V函数，并使用Bellman备份优化。
*   **主要步骤：** 1. 定义Flex-POMDP，包括状态、观察、行动和依赖函数。2.  rollout轨迹收集数据。3. 计算优势函数（如GAE）和目标值。4. 使用PPO优化策略和价值函数，支持LoRA微调以减少计算开销。算法框架在代码中实现，支持行动级和token级微调。

## Experiment

*   **数据集和设置：** 使用MATH数据集进行初步实验，环境初始化为随机采样的问题-答案对。代理基于配置文件（如reasoner和actor角色）协作解决问题，奖励为二元信号（正确/错误）。实验比较单代理和双代理框架，包括无调优基线、行动级PPO/token级PPO、行动级MARFT/token级MARFT。
*   **为什么这样设计：** 实验旨在验证MARFT在提升LaMAS性能方面的有效性，关注群智涌现和微调粒度对准确率的影响。设置合理，因为它控制变量（如代理数量、微调方法），并使用GAE和PPO确保稳定训练。
*   **结果分析：** MARFT显著提升准确率（如双代理MARFT达约50%，比基线高5%），但早期训练可能震荡（token级）。结果符合预期，显示MARFT在保持LLM能力的同时改善协作。实验全面，涵盖不同粒度和代理配置，并计划扩展到更多数据集如GSM8k和WebShop以验证泛化性。

## Further Thoughts 

MARFT的框架强调代理间的异步协作和动态组织，这可能与联邦学习相结合，提升隐私保护在分布式AI系统中的应用；此外，在区块链技术中，MARFT可优化去中心化自治组织（DAO）的决策过程，通过强化学习改进代理间的共识机制；与深度强化学习领域的MAT（Multi-Agent Transformer）类似，MARFT可扩展到更复杂的环境，如机器人群协作，潜在地解决样本效率问题，通过集成离线数据或元学习方法来加速收敛。