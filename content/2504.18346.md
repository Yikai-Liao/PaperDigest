---
title: "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review"
slug: "2504.18346"
description: "本文通过系统综述和实证基准测试，比较了LLMs的不确定性量化与校准方法，揭示了这些方法的有效性、局限性，并为未来研究提供了关键洞见。"
tags: ["Large Language Models", "Calibration", "Uncertainty Quantification", "Reliable Measurement"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:31:46.370804+00:00
preference: "unknown"
score: 0.5023664907595987
featured: false
draft: false
---

> 本文通过系统综述和实证基准测试，比较了LLMs的不确定性量化与校准方法，揭示了这些方法的有效性、局限性，并为未来研究提供了关键洞见。

> Large Language Models, Calibration, Uncertainty Quantification, Reliable Measurement 

> Toghrul Abbasli, Kentaroh Toyoda, Yuan Wang, Leon Witt, Muhammad Asif Ali, Yukai Miao, Dan Li, Qingsong Wei

> 清华大学, 新加坡科技研究局高性能计算研究所, 阿卜杜拉国王科技大学, 中关村实验室 

## Background Problem

大型语言模型（LLMs）在许多领域取得了革命性进展，但幻觉问题——即模型自信地输出错误信息——仍然是主要挑战之一。这引发了如何准确评估和量化LLMs不确定性的问题。传统模型的文献中已经探索了不确定性量化（UQ）来测量不确定性，并使用校准技术来解决不确定性和准确性之间的不一致。尽管一些方法已被适应用于LLMs，但现有文献缺乏对这些方法的深入分析和全面基准测试，导致无法进行有洞见的比较。本文旨在填补这一空白，通过系统综述代表性的先前工作并引入严格的基准测试，使用两个广泛使用的可靠性数据集，对六种相关方法进行实证评估，证明了综述的重要发现，并为关键未来方向提供展望。

## Method

* **核心思想：** 本文的核心是通过系统文献综述和实证评估来比较LLMs的不确定性测量和缓解方法，强调了不确定性（包括认识论不确定性和随机不确定性）的定义、量化方法（如贝叶斯神经网络、集成方法等）的适用性，以及校准技术的分类（开放盒、闭合盒和后验方法）。
* **工作原理：** 采用PRISMA系统文献综述框架，定义四个研究问题（RQ1：LLMs的不确定性定义；RQ2：现有校准方法；RQ3：方法在LLMs设置中的效果；RQ4：研究空白和新兴主题），通过关键词搜索和筛选相关文献，提取数据并进行分类。然后，通过生成式问答实验评估选定的方法，包括不确定性量化指标（如熵、置信度）和校准技术（如温度缩放、Platt缩放）。
* **主要步骤：** 1. 定义研究问题和文献审查协议；2. 识别和筛选相关研究；3. 分类不确定性和校准方法（如表II和表III所示）；4. 设计实验基准，使用TriviaQA和TruthfulQA数据集评估多个LLMs（如Llama 3.1、Mistral v0.3等）；5. 计算评估指标（如ECE、SmoothECE、Brier分数等）并分析结果。

## Experiment

* **数据集：** 使用TriviaQA（包含约95K问题-答案对，适合少样本学习）和TruthfulQA（817个问题，针对常见误区设计）两个数据集。TriviaQA用于训练12K样本和测试1.5K样本，TruthfulQA采用零样本设置，分半用于训练和测试。
* **实验设置：** 评估六种LLMs（Llama 3.1 8B、Mistral v0.3 7B、Qwen2.5 7B、GPT-4、GPT-4o、DeepSeek-R1），应用基线方法（如少样本学习、Chain-of-Thought、温度缩放、Platt缩放）和不确定性量化指标。指标包括ECE、SmoothECE、Brier分数、AUROC和BLEU分数，每个指标通过50次迭代采样以观察方差。实验设计旨在验证校准方法的有效性，理由是这些方法能更好地捕捉LLMs的置信度和准确性对齐。
* **结果：** 结果显示，温度缩放显著降低了ECE和SmoothECE分数，提高了模型校准（如在TruthfulQA上，Qwen2.5的ECE从0.187降至0.066）。模型规模影响不确定性：较小模型需要更好校准，而较大模型如GPT-4在基线时已较好校准。结果符合预期，因为校准方法改善了置信度-准确性对齐，但BLEU分数对长序列敏感，可能低估了Chain-of-Thought的性能。实验设置全面合理，覆盖了开放盒和闭合盒模型，并使用可靠性图（reliability diagrams）可视化结果。

## Further Thoughts 

论文中强调的不确定性量化方法可以扩展到多模态模型中，以提高AI系统的整体可靠性，例如在视觉-语言模型中结合语义熵来检测幻觉；此外，未来可探索不确定性与AI安全性的深度整合，如使用区块链技术为LLMs的校准提供可信激励机制，或通过自适应损失函数在分布偏移场景下提升模型鲁棒性，这些思路有助于将LLMs从单纯的生成工具转变为更可信的决策辅助系统。