---
title: "Harnessing Multiple Large Language Models: A Survey on LLM Ensemble"
slug: "2502.18036"
description: "\u672c\u6587\u9996\u6b21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684LLM Ensemble\u7efc\u8ff0\uff0c\u5305\u62ec\u7cfb\u7edf\u5206\u7c7b\u6cd5\u3001\u65b9\u6cd5\u56de\u987e\u3001\u57fa\u51c6\u548c\u672a\u6765\u65b9\u5411\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u548c\u6548\u7387\u3002"
tags: ["Large Language Model", "LLM Ensemble", "Taxonomy", "Routing", "Aggregation", "Benchmark", "Application"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:27:50.049439+00:00
preference: "dislike"
score: 0.7668543193667731
featured: false
draft: false
---

> 本文首次提供了一个全面的LLM Ensemble综述，包括系统分类法、方法回顾、基准和未来方向，旨在通过结合多个大语言模型提升任务性能和效率。

> Large Language Model, LLM Ensemble, Taxonomy, Routing, Aggregation, Benchmark, Application 

> Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu

> State Key Laboratory of Complex & Critical Software Environment, Beihang University, Beijing, China, Zhongguancun Laboratory, Beijing, China, Aviation System Engineering Institute of China, Beijing, China, Xi'an Jiaotong University, Xi'an, China, University of Macau, Macau SAR, China, University of Illinois at Chicago, Chicago, USA 

## Background Problem

大语言模型（LLMs）的快速发展导致了众多模型的出现，每个模型都具有不同的优势和劣势，但单个模型可能存在性能问题，如准确性不足、幻觉现象和与人类意图不一致等。同时，模型间的差异性（如架构、参数规模、训练数据）使得直接使用单一LLM来处理用户查询可能无法充分利用其潜力。本文的工作起点是借鉴集成学习的精神，通过结合多个LLM的独特优势来提升下游推理任务的性能和效率，解决的关键问题是缺乏对LLM Ensemble领域的系统性综述和分类，从而为研究者提供一个全面的框架，包括方法分类、相关问题、基准测试和未来方向。

## Method

本文的方法基于一个系统性的分类法，将LLM Ensemble方法分为三大类：（1）推理前集成（ensemble-before-inference），包括预训练路由器（classification-based、reward-based、assignment-based）和非预训练路由器；（2）推理中集成（ensemble-during-inference），包括token级集成（aggregation-based和selection-based）、span级集成（generation-assessment-selection pipeline）和过程级集成；（3）推理后集成（ensemble-after-inference），包括非级联方法（selection-based和selection-then-regeneration）和级联方法（基于deferral rule）。核心思想是通过这些分类回顾现有方法，总结其策略、粒度和目标，并在表格中提供详细分析，如在token级集成中处理词汇差异问题（e.g., 使用union dictionary或relative representation），或在级联方法中优化性能和成本 trade-off。回顾过程涉及数据准备、模型训练和评估步骤，但作为综述，主要依赖文献总结而非原创实现。

## Experiment

作为一篇综述论文，本文未进行原创实验，而是系统回顾了现有LLM Ensemble方法的实验设置和结果。所引用的方法在各种基准上进行了评估，例如MIXINSTRUCT基准用于测试集成性能，覆盖11个LLM和11K测试样本，ROUTERBENCH用于评估性能和成本平衡。实验设置包括生成任务、推理任务和分类任务，使用指标如准确率、成本、困惑度（perplexity，定义为 $$ \text{PPL}_k(S) = \exp\left\{-\frac{1}{t} \sum_{i=1}^{t} \log p_k(x_i \mid x_{<i})\right\} $$）等。结果显示，集成方法在保持或提升性能的同时（如通过token级聚合减少幻觉）可能降低成本，实验设计全面合理，覆盖了不同粒度和目标的场景，整体结果与预期一致，即 finer granularity 和 aggregation 策略通常带来更好性能改进。

## Further Thoughts 

LLM Ensemble 的概念可以扩展到其他AI领域，如计算机视觉中的模型集成，以提高系统的鲁棒性和泛化能力；未来可能结合联邦学习来处理分布式数据隐私问题，或使用强化学习动态优化集成策略以适应实时查询；此外，与弱监督学习相结合，能够在标签稀缺的环境中提升性能，并启发更高效的资源分配机制，类似于传统机器学习中的boosting和bagging方法，但需关注计算开销和模型异质性带来的挑战。