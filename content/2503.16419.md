---
title: "Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models"
slug: "2503.16419"
description: "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8c03\u67e5\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u63a8\u7406\u7684\u8fdb\u5c55\uff0c\u901a\u8fc7\u5206\u7c7b\u6a21\u578b\u3001\u8f93\u51fa\u548c\u63d0\u793a-based\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u51cf\u5c11\"\u8fc7\u5ea6\u601d\u8003\"\u73b0\u8c61\u7684\u7b56\u7565\uff0c\u4ee5\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u5e76\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u3002"
tags: ["Large Language Models", "Efficient Reasoning", "Chain-Of-Thought", "Overthinking Phenomenon", "Reinforcement Learning", "Supervised Fine-Tuning", "Dynamic Reasoning", "Prompt Engineering"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:26:28.930438+00:00
preference: "unknown"
score: 0.7651864724353022
featured: false
draft: false
---

> 本文首次系统调查了大型语言模型高效推理的进展，通过分类模型、输出和提示-based方法，探讨了减少"过度思考"现象的策略，以优化计算效率并保持推理能力。

> Large Language Models, Efficient Reasoning, Chain-Of-Thought, Overthinking Phenomenon, Reinforcement Learning, Supervised Fine-Tuning, Dynamic Reasoning, Prompt Engineering 

> Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu, Andrew Wen, Shaochen Zhong, Hanjie Chen, Xia Hu

> Rice University 

## Background Problem

本工作的出发点是解决大型语言模型（LLMs）在进行链式思考（CoT）推理时存在的"过度思考现象"，即模型生成冗长且冗余的推理序列，导致计算开销增加和响应延迟延长。具体问题背景包括：虽然较长的CoT推理能提升模型在系统2推理任务（如数学和编程）中的性能，但这会带来显著的计算负担，限制了模型在计算敏感的实际应用中的部署，例如实时自动驾驶、交互式对话助手和大规模在线搜索引擎。因此，本文旨在通过高效推理来优化推理长度，同时保持推理能力，以减少计算成本并提高实际可行性。

## Method

本文作为一篇调查性论文，并未提出新方法，而是系统地分类和总结了现有高效推理方法。核心思想是通过结构化调查来探索LLMs高效推理的进展，并将其分为三大类：（1）基于模型的效率改进，包括使用强化学习（RL）设计长度奖励（如PPO优化）或监督微调（SFT）使用可变长度CoT数据；（2）基于推理输出的效率改进，如将推理步骤压缩到更少的潜在表示中（例如使用连续思考或自蒸馏）或在推理过程中动态调整（如奖励引导或置信度-based自适应推理）；（3）基于输入提示的效率改进，如通过提示引导生成简洁推理或根据提示属性（如难度）进行路由。主要步骤包括：收集并分析现有文献，构建分类框架（如图2所示），并通过表格（如表1、表3）比较不同方法的细节，例如RL中的长度奖励公式或SFT中的数据构建方式。

## Experiment

作为调查论文，本文未进行原创实验，而是回顾和总结了现有研究的实验结果。实验设置包括多种数据集，如GSM8K、MATH、AIME-2024等，涵盖数学、逻辑和编程任务。实验设计合理且全面，评估了不同方法在保持准确率的同时减少推理长度的效果，例如RL方法（如O1-Pruner）在不降低准确率的情况下显著缩短CoT长度，SFT方法（如TokenSkip）通过跳过不重要token提高效率。结果显示方法改进明显，许多方法在推理效率和性能之间实现了良好权衡（如图5和图8所示），与预期一致，即高效推理能减少计算开销（如token生成减少）而不会显著牺牲准确率。调查还讨论了评估benchmark（如Sys2Bench），确保实验的全面性和合理性。

## Further Thoughts 

本文的调查启发我思考高效推理在实际应用中的潜力，例如在自动驾驶中，减少推理延迟可能提升实时决策的安全性；此外，结合其他领域如强化学习或小模型蒸馏，可能开发出更泛化的框架，但需注意权衡准确性和效率，避免过度优化导致泛化能力下降；未来可探索跨模态推理的效率改进，以适应多模态LLM的快速发展。