---
title: "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness"
slug: "2504.21773"
description: "\u672c\u6587\u63d0\u51faMAC-Tuning\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6b65\u5fae\u8c03\u5206\u79bb\u7b54\u6848\u9884\u6d4b\u548c\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u63d0\u5347LLMs\u5728\u591a\u95ee\u9898\u8bbe\u7f6e\u4e0b\u7684\u77e5\u8bc6\u8fb9\u754c\u610f\u8bc6\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u5e76\u6539\u5584\u6027\u80fd\u3002"
tags: ["LLM", "Multi-Problem", "Confidence Estimation", "Knowledge Boundary", "Hallucination", "Fine-Tuning"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:32:18.134262+00:00
preference: "unknown"
score: 0.6307842686459223
featured: false
draft: false
---

> 本文提出MAC-Tuning方法，通过分步微调分离答案预测和置信度估计，提升LLMs在多问题设置下的知识边界意识，显著减少幻觉并改善性能。

> LLM, Multi-Problem, Confidence Estimation, Knowledge Boundary, Hallucination, Fine-Tuning 

> Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung

> Hong Kong University of Science and Technology, University of Illinois, UMass Amherst 

## Background Problem

大型语言模型（LLMs）在知识密集型任务中广泛应用，但它们经常生成不存在的事实，称为幻觉问题，这会降低其可靠性。之前的相关研究主要关注单问题设置，即模型一次处理一个问题，而多问题设置（一个输入包含多个子问题，需要模型同时提取和回答）尚未得到充分探索。这种设置更具挑战性，可能导致上下文遮蔽和推理混乱，尤其是在涉及共享上下文的场景中（如任务指令或示例），因此本文旨在通过增强LLMs对知识边界的意识来改善多问题设置下的置信度估计，从而减少幻觉。

## Method

本文提出了一种名为Multiple Answers and Confidence Stepwise Tuning（MAC-Tuning）的方法，其核心思想是将答案预测和置信度估计的学习过程分开，以增强LLMs在多问题设置下的知识边界意识。具体实现包括几个关键步骤：首先，通过随机组合多个单问题构建多问题数据集，并利用该数据集与模型输出比较ground-truth答案来识别知识边界，标记每个问题的置信度标签（如"I am sure"或"I am unsure"）。然后，创建两个数据集：DMultQA用于答案预测对，输入为多个问题，输出为对应答案；DMultQA,C用于QA-置信度对，输入包括问题-答案对和置信度表达指令，输出为置信度水平。训练过程采用两步监督微调：第一步优化答案预测，目标函数为
$$
\max_{\Theta_0} \sum_{(Q,A)\in D_{MultiQA}} \log P(A|Q;\Theta_0)
$$
第二步优化置信度预测，目标函数为
$$
\max_{\Theta_1} \sum_{(Q,A,C)\in D_{MultiQA,C}} \log P(C|Q,A;\Theta_1)
$$
其中Q、A和C分别表示多个问题、答案和置信度集，\Theta_0和\Theta_1是模型参数。这种分步方法确保了模型在不牺牲答案准确性的前提下，提高了置信度校准能力。

## Experiment

实验设计全面且合理，旨在验证MAC-Tuning方法的有效性。使用多种数据集，包括独立设置（如CoQA、ParaRel、GSM、MMLU）和顺序设置（如MTI-Bench、SQA），这些数据集覆盖了问答和多选格式。实验设置了基线模型LLaMA3及其变体（如QA-Only、Single-QA、Merge-AC），并采用平均精度（AP）、期望校准误差（ECE）和准确率作为评估指标。AP用于衡量模型在正确和错误答案上的置信度排序精度，ECE用于评估预测置信度与实际正确性的匹配度，准确率计算模型在表达确定性的问题上正确回答的比例。结果显示，MAC-Tuning在所有数据集上均表现出色，AP分数比基线提高高达25%，ECE显著降低，准确率平均提升23.7%。这种改进符合预期，因为分步学习帮助模型更好地处理多问题设置中的知识边界。消融实验进一步证明了分离学习过程的重要性，而跨域和不同问题数量的分析显示了方法的泛化能力，例如在SQA上微调后测试其他数据集时，性能仍优于基线。实验开销合理，主要使用LoRA fine-tuning，资源消耗控制在Nvidia A100 GPU上。

## Further Thoughts 

本文的方法强调了在多问题设置下分离学习答案和置信度的优势，这可能启发在其他复杂推理任务中应用类似策略，例如结合检索增强生成（RAG）来进一步减少幻觉，或扩展到多模态设置以处理视觉和文本混合问题。同时，考虑到提示敏感性的局限性，未来可以探索更鲁棒的提示设计或无提示方法；此外，与Zhang et al. (2024)的灵感来源类似，将此方法与自洽性检查或多代理辩论结合，可能提升模型的泛化能力，尤其在实时应用中。