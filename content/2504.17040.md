---
title: "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs"
slug: "2504.17040"
description: "\u672c\u6587\u63d0\u51faDYMU\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4ee4\u724c\u5408\u5e76\u548c\u865a\u62df\u53d6\u6d88\u5408\u5e76\u7684\u8bad\u7ec3-free\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86VLMs\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u4fdd\u6301\u4e86\u4e0e\u5b8c\u6574\u6a21\u578b\u76f8\u4f3c\u7684\u6027\u80fd\u3002"
tags: ["Vision Language Model", "Token Merging", "Efficiency", "Dynamic Compression", "RoPE"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:29:06.935062+00:00
preference: "unknown"
score: 0.6391008389157905
featured: false
draft: false
---

> 本文提出DYMU框架，通过动态令牌合并和虚拟取消合并的训练-free方法，显著提高了VLMs的计算效率，同时在多个基准上保持了与完整模型相似的性能。

> Vision Language Model, Token Merging, Efficiency, Dynamic Compression, RoPE 

> Zhenhailong Wang, Senthil Purushwalkam, Caiming Xiong, Silvio Savarese, Heng Ji, Ran Xu

> University of Illinois Urbana-Champaign, Salesforce Research 

## Background Problem

本工作的起点是解决视觉语言模型（VLMs）中的计算效率问题。VLMs通常使用视觉编码器提取图像特征，并生成固定长度的视觉令牌，这些令牌数量不依赖于图像内容的复杂性，导致不必要的计算开销。例如，在处理高分辨率图像时，视觉令牌可能占主导地位，而简单图像也使用相同数量的令牌，造成资源浪费。论文解决了关键问题：如何动态调整视觉令牌的数量以适应图像复杂性，同时在不进行额外训练的情况下保持模型性能，从而减少计算负担并提高VLMs的实际应用效率。

## Method

* **核心思想：** DYMU框架旨在通过训练-free的方法动态减少VLMs中的视觉令牌数量，同时保持下游任务性能。具体来说，它包括动态令牌合并（DToMe）和虚拟令牌取消合并（VTU）两个组件，前者针对视觉编码器，后者针对语言模型解码器。
* **如何实现：** DToMe基于图像复杂性合并相似的视觉令牌，使用二部图软匹配策略：首先，将令牌分为两组A和B，然后通过相似性得分$S^i[t] = (k^i[t]^T k^i[t_B])$选择得分高于阈值$\tau^i$的边进行合并，合并公式为$x_i[t_B] \leftarrow \frac{x_i[t] \cdot |\mathbf{P}_i[t]| + x_i[t_B] \cdot |\mathbf{P}_i[t_B]|}{|\mathbf{P}_i[t]| + |\mathbf{P}_i[t_B]|}$，并更新位置集$\mathbf{P}_i[t_B] \leftarrow \mathbf{P}_i[t_B] \cup \mathbf{P}_i[t]$。阈值$\tau^i$通过批量图像计算，确保平均合并令牌数符合预设。VTU则在语言模型中使用RoPE，重建注意力矩阵，例如$A = CMQ_{\text{un}}K_{\text{un}}^{\top}M^{\top}C + SMQ_{\text{un}}K_{\text{un}}^{\top}M^{\top}S + SM(Q_{\text{un}} \times K_{\text{un}}^{\top})M^{\top}C - CM(Q_{\text{un}} \times K_{\text{un}}^{\top})M^{\top}S$，以模拟完整序列，而不实际扩展令牌。
* **主要步骤：** 首先，使用多样图像批量计算层级阈值；推理时，对每个图像动态合并视觉令牌；然后在语言模型中应用VTU重建注意力动态，并重新合并令牌以减少计算。

## Experiment

* **实验设置：** 论文在多个基准上评估DYMU，包括GQA、MMBench、MME、POPE、ScienceQA、SEED-IMG、TextVQA、MMVet和LLaVA-Bench等。实验使用不同VLM架构，如LLaVA-1.5和LLaVA-OneVision，视觉编码器包括CLIP和SigLIP。DYMU的变体（low、mid、high）通过设置不同平均令牌减少率来测试，阈值基于LLaVA指令调优数据计算。实验设计全面，涵盖定量评估（如性能与令牌减少率）、消融实验（如VTU的影响、阈值数据集敏感性）和定性分析（如图像复杂性与令牌数的相关性）。
* **结果：** DYMU在减少视觉令牌32%-85%的情况下，性能保持在基线水平的97.7%-100.4%，例如DYMU-low在LLaVA-1.5上平均性能为54.5，与完整模型的55.8相近。相比固定长度方法，DYMU在复杂图像上表现更好，消融实验显示VTU显著提升性能。结果符合预期，证明了动态调整的有效性和训练-free方法的实用性，同时实验开销低，仅增加少量计算。
* **是否符合预期：** 是，实验结果显示方法改进明显，效率提升显著，且实验设置合理全面，验证了DYMU的鲁棒性和泛化能力。

## Further Thoughts 

这个方法启发了在其他模态如视频或3D数据中应用动态压缩技术，以减少冗余信息；此外，可以探索与高级视觉工具（如背景移除或物体检测）的结合，进一步提升效率；同时，针对空间敏感任务如TextVQA，未来可融入更多先验知识来最小化性能损失；这也与模型蒸馏或稀疏注意力机制相关，潜在地推动更泛化的高效多模态模型发展。