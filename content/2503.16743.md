---
title: "SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability"
slug: "2503.16743"
description: "\u672c\u6587\u63d0\u51faSuperARC\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u7b97\u6cd5\u6982\u7387\u548cKolmogorov\u590d\u6742\u5ea6\u7684\u539f\u7406\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5ba2\u89c2\u7684AGI\u548cASI\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bc1\u660e\u9012\u5f52\u538b\u7f29\u7b49\u4ef7\u4e8e\u9884\u6d4b\uff0c\u5e76\u5c55\u793a\u4e86LLMs\u7684\u5c40\u9650\u6027\u3002"
tags: ["Algorithmic Complexity", "Kolmogorov Complexity", "Artificial Intelligence", "Superintelligence", "Causal AI", "Symbolic Regression", "Neurosymbolic Computation"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:26:52.328491+00:00
preference: "unknown"
score: 0.5484211501910764
featured: false
draft: false
---

> 本文提出SuperARC测试框架，通过算法概率和Kolmogorov复杂度的原理，设计了一个客观的AGI和ASI评估方法，证明递归压缩等价于预测，并展示了LLMs的局限性。

> Algorithmic Complexity, Kolmogorov Complexity, Artificial Intelligence, Superintelligence, Causal AI, Symbolic Regression, Neurosymbolic Computation 

> Alberto Hernández-Espinosa, Luan Ozelim, Felipe S. Abrahão, Hector Zenil

> Oxford University, London Institute for Healthcare Engineering, Karolinska Institute, King's College London, University of Campinas, National Laboratory for Scientific Computing 

## Background Problem

本研究的出发点是针对人工智能（AI）领域的AGI（人工通用智能）和ASI（超级智能）评估需求，提出一个基于算法概率的客观定量测试，以避免基准测试污染和人类中心偏见。论文指出，现有测试（如基于人类IQ测试或Turing测试）往往依赖统计压缩方法（如GZIP或LZW），这些方法更接近Shannon熵而非Kolmogorov复杂度，无法有效测试AI的根本智能特征，如合成、模型创建和逆问题求解。LLMs（大型语言模型）被批评为主要依赖记忆和统计模式匹配，而非批判性思考或一般智能，因此需要一个框架来评估AI的抽象、预测和规划能力，以揭示其在AGI和ASI方面的局限性。

## Method

*   **核心思想:** 本文提出SuperARC框架，利用算法信息理论（AIT）的原理，包括算法概率和Kolmogorov复杂度，定义智能为创建可计算模型的能力，以尽可能无损地解释数据，并通过递归压缩和预测来量化智能。核心是证明压缩与预测等价，即系统能更好地压缩数据，就能更好地预测，反之亦然。
*   **实现方式:** 使用块分解方法（BDM）和编码定理方法（CTM）来近似算法复杂度。BDM将对象分解为小块，计算每个块的CTM复杂度，并结合Shannon熵修正因子；CTM基于算法概率估计算法复杂度。测试框架包括生成模型或程序来重现序列，并评估压缩和预测能力。公式为：$$\text{BDM}(x) = \sum_{i=1}^{n} \text{CTM}(x_i) + \log m_i$$，其中CTM基于算法概率近似局部复杂度。SuperARC测试通过动态生成序列，避免固定数据集的泄漏问题。
*   **主要步骤:** (1) 编码输入数据；(2) 使用代理模型生成序列；(3) 评估压缩和预测性能；(4) 比较LLMs与BDM/CTM方法的表现。

## Experiment

*   **数据集和设置:** 使用二进制和整数序列，分为低、中、高复杂度组。实验包括下一位数字预测、自由形式生成和代码生成任务。LLMs（如GPT-4o、Claude 3.5 Sonnet等）被测试其在不同复杂度的序列上的性能，比较指标包括准确率、压缩率、相似度（如Levenshtein距离）。设置合理全面，因为它动态生成序列以避免基准污染，并使用多种模型和指标验证。
*   **为什么这样设计:** 目的是测试AI的抽象和预测能力，而非记忆。BDM/CTM作为基准，证明其在复杂序列上的优越性。实验验证了压缩与预测的等价性，并暴露LLMs的局限性，如依赖模式匹配而非因果推理。
*   **结果和预期匹配:** LLMs在简单序列上表现良好，但复杂度增加时准确率下降，倾向于简单输出（如打印序列），而BDM/CTM在预测和压缩上优于LLMs，符合预期，证明LLMs缺乏真正智能。

## Further Thoughts 

本文的灵感在于算法概率与Kolmogorov复杂度的等价性，这不仅适用于AI测试，还可扩展到其他领域，如生物信息学中的模式识别或医疗诊断中的因果推理；与ARC挑战类似，SuperARC强调动态生成测试以避免数据泄漏，这启发未来AI基准应整合符号计算与统计方法，实现更鲁棒的泛化；此外，BDM/CTM的神经符号方法可能与深度学习模型结合，提升LLMs的因果推理能力，但需注意计算开销；从进化角度看，这种框架可用于模拟自然选择过程，探索智能的演化机制。