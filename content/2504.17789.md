---
title: "Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models"
slug: "2504.17789"
description: "本文提出Token-Shuffle方法，通过利用视觉词汇维度冗余动态合并和恢复图像令牌，实现高效的高分辨率文本到图像生成，同时在统一自回归框架下保持出色性能。"
tags: ["Autoregressive Model", "Image Generation", "Token Shuffle", "Multimodal Large Language Model", "High Resolution"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:31:22.628685+00:00
preference: "unknown"
score: 0.5994832633487314
featured: false
draft: false
---

> 本文提出Token-Shuffle方法，通过利用视觉词汇维度冗余动态合并和恢复图像令牌，实现高效的高分辨率文本到图像生成，同时在统一自回归框架下保持出色性能。

> Autoregressive Model, Image Generation, Token Shuffle, Multimodal Large Language Model, High Resolution 

> Xu Ma, Peize Sun, Haoyu Ma, Hao Tang, Chih-Yao Ma, Jialiang Wang, Kunpeng Li, Xiaoliang Dai, Yujun Shi, Xuan Ju, Yushi Hu, Artsiom Sanakoyeu, Felix Juefei-Xu, Ji Hou, Junjiao Tian, Tao Xu, Tingbo Hou, Yen-Cheng Liu, Zecheng He, Zijian He, Matt Feiszli, Peizhao Zhang, Peter Vajda, Sam Tsai, Yun Fu

> Northeastern University, Meta GenAI, Meta FAIR, National University of Singapore, The Chinese University of Hong Kong, University of Washington 

## Background Problem

本工作的出发点是解决自回归（AR）模型在图像生成中的关键问题。AR模型虽然在语言生成中表现出色，但应用于图像合成时，由于需要处理大量图像令牌，导致训练和推理效率低下，尤其是高分辨率图像的生成。相比扩散模型，AR模型在计算复杂度上更易受限于Transformer的二次方复杂度，这限制了图像分辨率的提升和细节保留。论文背景指出，多模态大语言模型（MLLMs）中视觉词汇的维度冗余被忽略，直接将低维视觉编码映射到高维语言词汇中，造成无效计算。研究旨在通过减少图像令牌数量来提高效率，同时保持生成质量。

## Method

核心思想是利用视觉词汇的维度冗余，通过Token-Shuffle方法减少Transformer输入的视觉令牌数量。具体实现包括两个关键操作：token-shuffle和token-unshuffle。token-shuffle操作将空间局部$s \times s$的视觉令牌沿通道维度合并为一个令牌，使用共享的MLP层压缩维度（如从$d$到$d/s^2$），减少令牌数量；token-unshuffle操作在Transformer输出后恢复原令牌，使用MLP层扩展维度并恢复空间排列。整个过程还包括残差MLP块增强特征融合，保持因果掩码不变，支持统一的自回归下一令牌预测框架。论文还引入CFG调度器（如半线性调度），在推理时动态调整CFG比例，提高文本对齐和视觉质量，避免早期令牌的干扰。

## Experiment

实验使用类似Emu的许可数据集，分为三个训练阶段：先在512×512分辨率下预训练无Token-Shuffle操作，然后逐步提升到1024×1024和2048×2048分辨率，引入Token-Shuffle操作以提高效率。高分辨率训练采用z-loss稳定损失和梯度，序列长度为4096，批量大小为512。评估基准包括GenAI-Bench和GenEval，使用VQAScore（基于微调的VQA模型）和人工评估，数据集包括重写的长提示以匹配训练数据。实验结果显示，2.7B模型在硬提示上获得0.77的整体分数，优于AR模型LlamaGen（提升0.18）和扩散模型LDM（提升0.15），在文本对齐、视觉外观上表现突出，但视觉缺陷稍逊。实验设置全面合理，包括消融研究（如shuffle窗口大小、CFG比例），结果符合预期，证明了方法在效率和性能上的显著改进。

## Further Thoughts 

Token-Shuffle的方法灵感来源于像素洗牌技术，值得关注的是它通过利用维度冗余实现了高效的令牌压缩，这可能扩展到其他模态如视频生成或3D建模中，进一步提升多模态模型的泛化能力。与扩散模型相比，AR模型在统一框架下的潜力更大，但存在视觉缺陷问题（如结构错误），未来可结合RAR等方法引入全局交互改进；此外，与Fluid文章类似，探索连续令牌的整合可能进一步优化AR模型的生成质量；同时，Token-Shuffle的plug-and-play设计为资源受限场景提供灵感，如移动端应用，但需注意高分辨率训练的稳定性挑战。