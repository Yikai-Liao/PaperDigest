---
title: "Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare"
slug: "2504.21191"
description: "本文通过实证实验指导在医疗专业应用中语言模型的选择，强调微调小语言模型和领域特定预训练的显著优势，使其在特定任务上超越零-shot 大语言模型。"
tags: ["Language Model", "Zero-Shot Learning", "Finetuning", "Small Language Model", "Large Language Model", "Healthcare", "Classification", "Domain Adaptation"]
author: "grok-3-mini-latest"
pubDatetime: 2025-05-04T08:31:39.820466+00:00
preference: "unknown"
score: 0.672436873155613
featured: false
draft: false
---

> 本文通过实证实验指导在医疗专业应用中语言模型的选择，强调微调小语言模型和领域特定预训练的显著优势，使其在特定任务上超越零-shot 大语言模型。

> Language Model, Zero-Shot Learning, Finetuning, Small Language Model, Large Language Model, Healthcare, Classification, Domain Adaptation 

> Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng

> Provincial Health Services Authority, University of British Columbia 

## Background Problem

语言模型的快速发展为自然语言处理带来了革命，但也引发了在专业领域如医疗中的模型选择难题。本文的研究起点是探讨在医疗应用中如何选择合适的语言模型，解决的关键问题是：1) 是否需要对模型进行微调，还是可以直接使用零-shot 能力；2) 领域相关预训练模型是否优于通用预训练模型；3) 进一步进行领域特定预训练是否有价值；4) 在大型语言模型（LLM）兴起的时代，小语言模型（SLM）是否仍具相关性。通过使用英国哥伦比亚癌症登记处（BCCR）的电子病理报告数据，本文提供了实证证据来指导这些决策，帮助从业者在资源受限的环境中优化模型性能和效率。

## Method

本文的方法基于实证实验评估不同语言模型的选择策略。核心思想是通过比较零-shot 和微调方法、领域相关 vs 通用预训练模型、以及进一步领域特定预训练的影响，来指导模型选择。主要步骤包括：1) 定义三个分类任务场景，代表不同难度和数据规模；2) 选择多种现成模型，包括 SLM（如 RoBERTa、pathologyBERT、Gatortron）和 LLM（如 Mistral）；3) 对于 SLM，进行零-shot 和微调评估；4) 对于部分 SLM，进行进一步预训练（如使用 Masked Language Modeling 预训练）；5) 使用宏平均 F1 分数作为性能指标，评估模型在不同场景下的表现。这种方法强调了模型适应的动态过程，旨在最小化资源消耗的同时最大化任务性能。

## Experiment

实验使用 BCCR 的电子病理报告数据，设置三个分类场景以覆盖常见临床 NLP 挑战：a) 易的二分类任务（报告性分类），大样本（训练 40,000 条，测试 20,400 条），目的是分类报告是否可报告；b) 中的多分类任务（肿瘤组分类），有限样本（训练 16,000 条，测试 2,058 条），分类为 19 个肿瘤组；c) 难的多分类任务（组织学分类），小样本（训练 1,000 条，测试 447 条），分类为六种常见白血病组织学代码。这种设置合理，因为它模拟了现实中任务复杂度和数据可用性的变异。模型包括 SLM 的零-shot 和微调版本，以及 LLM 的零-shot 版本；进一步预训练了 RoBERTa 和 Gatortron。结果显示：微调显著提升 SLM 性能（零-shot F1 分数为 0.34-0.40、0.01、0.02-0.13，微调后为 0.95-0.97、0.78-0.85、0.60-0.78）；零-shot LLM 优于零-shot SLM 但逊于微调 SLM；领域相关模型微调后在复杂任务中表现更好，进一步预训练在数据稀缺场景中收益显著（如场景 c 中 BCCRTron F1 分数达 0.89）。实验结果符合预期，验证了领域适应理论，并突出了微调和预训练的价值。

## Further Thoughts 

本文强调了在专业领域微调 SLM 的重要性，这启发我们探索其他领域如金融或法律的 NLP 应用中类似策略，可能通过结合主动学习减少标注数据需求；此外，它与迁移学习原理一致，提醒我们在 LLM 时代关注性能与资源效率的权衡，未来可研究 SLM 和 LLM 的混合框架，以提升泛化能力和隐私保护。