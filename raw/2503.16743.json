{
    "title": "SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability",
    "authors": [
        "Alberto Hernández-Espinosa",
        "Luan Ozelim",
        "Felipe S. Abrahão",
        "Hector Zenil"
    ],
    "institution": [
        "Oxford University",
        "London Institute for Healthcare Engineering",
        "Karolinska Institute",
        "King's College London",
        "University of Campinas",
        "National Laboratory for Scientific Computing"
    ],
    "problem_background": "本研究的出发点是针对人工智能（AI）领域的AGI（人工通用智能）和ASI（超级智能）评估需求，提出一个基于算法概率的客观定量测试，以避免基准测试污染和人类中心偏见。论文指出，现有测试（如基于人类IQ测试或Turing测试）往往依赖统计压缩方法（如GZIP或LZW），这些方法更接近Shannon熵而非Kolmogorov复杂度，无法有效测试AI的根本智能特征，如合成、模型创建和逆问题求解。LLMs（大型语言模型）被批评为主要依赖记忆和统计模式匹配，而非批判性思考或一般智能，因此需要一个框架来评估AI的抽象、预测和规划能力，以揭示其在AGI和ASI方面的局限性。",
    "method": "*   **核心思想:** 本文提出SuperARC框架，利用算法信息理论（AIT）的原理，包括算法概率和Kolmogorov复杂度，定义智能为创建可计算模型的能力，以尽可能无损地解释数据，并通过递归压缩和预测来量化智能。核心是证明压缩与预测等价，即系统能更好地压缩数据，就能更好地预测，反之亦然。\n*   **实现方式:** 使用块分解方法（BDM）和编码定理方法（CTM）来近似算法复杂度。BDM将对象分解为小块，计算每个块的CTM复杂度，并结合Shannon熵修正因子；CTM基于算法概率估计算法复杂度。测试框架包括生成模型或程序来重现序列，并评估压缩和预测能力。公式为：$$\\text{BDM}(x) = \\sum_{i=1}^{n} \\text{CTM}(x_i) + \\log m_i$$，其中CTM基于算法概率近似局部复杂度。SuperARC测试通过动态生成序列，避免固定数据集的泄漏问题。\n*   **主要步骤:** (1) 编码输入数据；(2) 使用代理模型生成序列；(3) 评估压缩和预测性能；(4) 比较LLMs与BDM/CTM方法的表现。",
    "experiment": "*   **数据集和设置:** 使用二进制和整数序列，分为低、中、高复杂度组。实验包括下一位数字预测、自由形式生成和代码生成任务。LLMs（如GPT-4o、Claude 3.5 Sonnet等）被测试其在不同复杂度的序列上的性能，比较指标包括准确率、压缩率、相似度（如Levenshtein距离）。设置合理全面，因为它动态生成序列以避免基准污染，并使用多种模型和指标验证。\n*   **为什么这样设计:** 目的是测试AI的抽象和预测能力，而非记忆。BDM/CTM作为基准，证明其在复杂序列上的优越性。实验验证了压缩与预测的等价性，并暴露LLMs的局限性，如依赖模式匹配而非因果推理。\n*   **结果和预期匹配:** LLMs在简单序列上表现良好，但复杂度增加时准确率下降，倾向于简单输出（如打印序列），而BDM/CTM在预测和压缩上优于LLMs，符合预期，证明LLMs缺乏真正智能。",
    "one_sentence_summary": "本文提出SuperARC测试框架，通过算法概率和Kolmogorov复杂度的原理，设计了一个客观的AGI和ASI评估方法，证明递归压缩等价于预测，并展示了LLMs的局限性。",
    "slug": "superarc-agnostic-intelligence-test",
    "keywords": [
        "Algorithmic Complexity",
        "Kolmogorov Complexity",
        "Artificial Intelligence",
        "Superintelligence",
        "Causal AI",
        "Symbolic Regression",
        "Neurosymbolic Computation"
    ],
    "further_thoughts": "本文的灵感在于算法概率与Kolmogorov复杂度的等价性，这不仅适用于AI测试，还可扩展到其他领域，如生物信息学中的模式识别或医疗诊断中的因果推理；与ARC挑战类似，SuperARC强调动态生成测试以避免数据泄漏，这启发未来AI基准应整合符号计算与统计方法，实现更鲁棒的泛化；此外，BDM/CTM的神经符号方法可能与深度学习模型结合，提升LLMs的因果推理能力，但需注意计算开销；从进化角度看，这种框架可用于模拟自然选择过程，探索智能的演化机制。",
    "model": "grok-3-mini-latest",
    "temperature": 0.5,
    "top_p": 0.7,
    "lang": "zh",
    "id": "2503.16743",
    "preference": "unknown",
    "summary_time": "2025-05-04T08:26:52.328491+00:00",
    "score": 0.5484211501910764,
    "abstract": "We introduce an open-ended test grounded in algorithmic probability that can avoid benchmark contamination in the quantitative evaluation of frontier models in the context of their Artificial General Intelligence (AGI) and Superintelligence (ASI) claims. Unlike other tests, this test does not rely on statistical compression methods (such as GZIP or LZW), which are more closely related to Shannon entropy than to Kolmogorov complexity and are not able to test beyond simple pattern matching. The test challenges aspects of AI, in particular LLMs, related to features of intelligence of fundamental nature such as synthesis and model creation in the context of inverse problems (generating new knowledge from observation). We argue that metrics based on model abstraction and abduction (optimal Bayesian `inference') for predictive `planning' can provide a robust framework for testing intelligence, including natural intelligence (human and animal), narrow AI, AGI, and ASI. We found that LLM model versions tend to be fragile and incremental as a result of memorisation only with progress likely driven by the size of training data. The results were compared with a hybrid neurosymbolic approach that theoretically guarantees universal intelligence based on the principles of algorithmic probability and Kolmogorov complexity. The method outperforms LLMs in a proof-of-concept on short binary sequences. We prove that compression is equivalent and directly proportional to a system's predictive power and vice versa. That is, if a system can better predict it can better compress, and if it can better compress, then it can better predict. Our findings strengthen the suspicion regarding the fundamental limitations of LLMs, exposing them as systems optimised for the perception of mastery over human language.",
    "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
    ],
    "created": "2025-04-22",
    "updated": "2025-04-24"
}