{
    "title": "Beyond Public Access in LLM Pre-Training Data",
    "authors": [
        "Sruly Rosenblat",
        "Tim O'Reilly",
        "Ilan Strauss"
    ],
    "institution": [
        "Social Science Research Council",
        "O'Reilly Media",
        "AI Disclosures Project"
    ],
    "problem_background": "大型语言模型（LLMs）在預訓練階段需要大量公共和非公共數據，但數據來源和法律狀態通常未被公司披露。多家AI公司可能在未經許可的情況下使用非公共、經常是非法獲得的內容進行訓練，本文以合法獲得的34本O'Reilly Media版權書籍為數據集，應用DE-COP成員推斷攻擊方法，調查OpenAI的模型是否在未經同意的情況下使用了版權內容。研究發現，GPT-4o對付費牆後的O'Reilly書籍內容有較強識別能力（$AUROC = 82\\%$），而GPT-3.5 Turbo則較弱，這突顯了增加公司透明度並制定正式許可框架的迫切需求，以保護內容創作者的權益並維持互聯網的商業模式。",
    "method": "*   **核心思想：** 使用DE-COP成員推斷攻擊方法，通過測試模型是否能區分人類編寫的原始文本和AI生成的改寫版本，來推斷模型是否在訓練中見過該文本，從而檢測未經授權的數據使用。\n*   **具體實現：** 首先，將書籍數據分為公共和非公共部分，並根據模型訓練截止日期分為可能在數據集內（出版於截止日期前）和明確不在數據集內（出版於截止日期後）的樣本。然後，使用Claude 3.5 Sonnet生成文本的改寫版本，對OpenAI模型進行多選測試，計算猜中率（guess rate）。最後，使用AUROC分數量化模型的區分能力，評估模型對潛在訓練數據的識別程度。關鍵步驟包括數據分割、改寫生成、模型測試和性能評估，無需修改模型本身，只依賴於輸出分析。",
    "experiment": "*   **數據集和設置：** 使用34本O'Reilly書籍的數據集，共13962個段落，分為公共（章節開頭1500字或特定章節）和非公共部分。模型包括GPT-3.5 Turbo（訓練截止2021年9月）、GPT-4o和GPT-4o Mini（訓練截止2023年10月）。實驗設計考慮了時間偏差，通過測試相同截止日期的模型來驗證結果，並使用分層自助抽樣計算置信區間。\n*   **為何這樣設計：** 這種設置能區分模型對公共和非公共數據的識別能力，同時控制時間相關偏差，確保結果主要反映訓練數據的影響而非語言變化。\n*   **結果：** GPT-4o對非公共數據的書本級AUROC分數為82%，高於公共數據的64%，表明可能訓練過非公共內容；GPT-3.5 Turbo的非公共AUROC僅54%，公共為64%，顯示較早模型更依賴公共數據。結果符合預期，證明較新模型更可能使用非公共數據。實驗設置全面合理，樣本大小適中，但局限性包括對小型模型（如GPT-4o Mini，AUROC約50%）的測試難度較大，以及書本級AUROC的置信區間較寬（可能因書籍數量有限）。總體而言，實驗證實了方法的有效性，並強調了非公共數據在模型訓練中的重要性。",
    "one_sentence_summary": "本文通過DE-COP成員推斷攻擊方法，使用O'Reilly書籍數據集證明OpenAI的GPT-4o可能訓練過非公共版權內容，突顯了LLM預訓練數據中非公共數據使用增加的趨勢及加強透明度和許可框架的必要性。",
    "slug": "beyond-public-access-llm-pretraining-data",
    "keywords": [
        "Membership Inference Attacks",
        "Large Language Models",
        "Copyright Issues",
        "Data Access Violations",
        "Pre-Training Data",
        "Architecture of Participation"
    ],
    "further_thoughts": "這項研究揭示了AI模型訓練中版權問題的嚴重性，可能激發開發更先進的數據追蹤技術，如水印或影響函數，以精確識別訓練數據來源；同時，結合歐盟AI法案等政策討論，提示需要建立公平的AI內容市場，平衡創新與創作者權益，避免內容生態崩潰；未來，可以探索將類似方法應用到其他領域，如圖像或音樂的版權檢測，促進跨領域的AI倫理研究。",
    "model": "grok-3-mini-latest",
    "temperature": 0.5,
    "top_p": 0.7,
    "lang": "zh",
    "id": "2505.00020",
    "preference": "unknown",
    "summary_time": "2025-05-04T08:32:25.312674+00:00",
    "score": 0.5366993500051981,
    "abstract": "Using a legally obtained dataset of 34 copyrighted O'Reilly Media books, we apply the DE-COP membership inference attack method to investigate whether OpenAI's large language models were trained on copyrighted content without consent. Our AUROC scores show that GPT-4o, OpenAI's more recent and capable model, demonstrates strong recognition of paywalled O'Reilly book content (AUROC = 82\\%), compared to OpenAI's earlier model GPT-3.5 Turbo. In contrast, GPT-3.5 Turbo shows greater relative recognition of publicly accessible O'Reilly book samples. GPT-4o Mini, as a much smaller model, shows no knowledge of public or non-public O'Reilly Media content when tested (AUROC $\\approx$ 50\\%). Testing multiple models, with the same cutoff date, helps us account for potential language shifts over time that might bias our findings. These results highlight the urgent need for increased corporate transparency regarding pre-training data sources as a means to develop formal licensing frameworks for AI content training",
    "categories": [
        "cs.CL",
        "cs.AI"
    ],
    "created": "2025-04-24",
    "updated": "2025-05-02"
}