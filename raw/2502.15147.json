{
    "title": "Latent Factor Models Meets Instructions: Goal-conditioned Latent Factor Discovery without Task Supervision",
    "authors": [
        "Zhouhang Xie",
        "Tushar Khot",
        "Bhavana Dalvi Mishra",
        "Harshit Surana",
        "Julian McAuley",
        "Peter Clark",
        "Bodhisattwa Prasad Majumder"
    ],
    "institution": [
        "University of California, San Diego",
        "Allen Institute for AI"
    ],
    "problem_background": "本研究的起点是解决从非结构化数据中发现可解释潜在结构的长期挑战，特别是当发现过程需要根据用户以自然语言表达的目标进行适应时。传统方法如潜在狄利克雷分配（LDA）和BertTopic虽然在挖掘潜在模式方面有效，但无法灵活响应用户指令，而基于大型语言模型（LLMs）的框架虽能根据指令调整行为，却在处理大规模噪声数据时表现不佳，因为它们依赖LLMs的推理能力，且在数据超出LLMs知识范围或噪声较大时效果下降。本文解决了关键问题，包括在没有任务特定监督的情况下，实现目标导向的潜在因素发现、处理噪声数据、提高发现结果的连贯性和相关性，以及提升下游任务性能。",
    "method": "本文提出的方法是Instruct-LF框架，核心思想是将LLMs的指令遵循能力与经典梯度-based统计模型相结合，以最小化对LLMs推理能力的依赖。具体实现包括两个主要步骤：首先，进行目标导向的数据转换，包括属性提案（property proposal）阶段，通过提示LLMs基于每个数据点生成细粒度的目标相关属性描述；然后，进行数据-属性链接预测，使用一个双嵌入模型（基于神经矩阵分解）训练以高效估计每个数据点与属性的兼容性分数，避免了昂贵的LLM调用。公式为：\n$$\\text{score}(c, x) = \\Phi(c)^T \\Phi(x), \\tag{1}$$\n其中，\\Phi是编码器，c是属性，x是数据点。损失函数使用批处理负采样：\n$$\\mathbf{p}(c|x) = \\frac{\\exp(\\text{score}(c|x))}{\\sum_{j=1}^{K} \\exp(\\text{score}(c|x))}, \\qquad (2)$$\n接着，在潜在因素发现阶段，使用Linear Corex模型对属性进行基于协方差的聚类，优化总相关性损失以将高度相关的属性分组为更高层次的概念：\n$$TC(Y) = \\sum_{i=1}^{N} H(Y_i) - H(Y), \\qquad (4)$$\n确保每个属性仅分配到一个潜在维度，从而提高可解释性。",
    "experiment": "实验评估了Instruct-LF在三个场景中的性能：(1) 电影推荐任务，使用Inspired数据集，评估指标为Hit@k（k=1,5,20），结果显示Instruct-LF在保持教师模型准确率的同时显著提高了推荐性能，比基线提升5-52%；(2) 具身导航任务，使用Alfworld数据集，预测下一个动作的准确率，在已见和未见任务上均优于基线；(3) 法律文档分类任务，使用American Bills数据集，采用决策树探针评估高层次和细粒度主题分类准确率。实验设置全面合理，包括了自动评估（与基线如LDA、BERTopic、TopicGPT比较）和人工评估（任务相关性、信息性和整体偏好），结果符合预期，证明了Instruct-LF在噪声数据上的鲁棒性和目标适应性，尤其是在LLM能力较弱时（如使用Mistral-7B）仍能保持性能，而基线方法在噪声数据上失败。",
    "one_sentence_summary": "本文提出Instruct-LF方法，通过结合LLMs的指令遵循能力和梯度-based统计模型，实现无需任务监督的目标导向潜在因素发现，提高了下游任务性能并在人工评估中被偏好。",
    "slug": "latent-factor-models-meets-instructions",
    "keywords": [
        "Latent Factor Models",
        "Instruction Following",
        "Large Language Models",
        "Goal-Conditioned Discovery",
        "Latent Factor Discovery",
        "Property Proposal",
        "Gradient-Based Optimization"
    ],
    "further_thoughts": "本文的Instruct-LF框架启发我们思考如何将LLMs的生成能力与传统统计模型相结合，以减少对强大LLMs的依赖，并扩展到其他领域，如解释性AI中的概念瓶颈模型（Concept Bottleneck Models），或在医疗数据挖掘中用于目标导向的患者分组；此外，未来可探索使用更高效的属性生成策略或替代兼容性度量（如余弦相似度），以进一步提升泛化能力和效率，同时需注意LLMs幻觉问题的潜在风险。",
    "model": "grok-3-mini-latest",
    "temperature": 0.5,
    "top_p": 0.7,
    "lang": "zh",
    "id": "2502.15147",
    "preference": "unknown",
    "summary_time": "2025-05-04T08:27:29.451992+00:00",
    "score": 0.5969654671465184,
    "abstract": "Instruction-following LLMs have recently allowed systems to discover hidden concepts from a collection of unstructured documents based on a natural language description of the purpose of the discovery (i.e., goal). Still, the quality of the discovered concepts remains mixed, as it depends heavily on LLM's reasoning ability and drops when the data is noisy or beyond LLM's knowledge. We present Instruct-LF, a goal-oriented latent factor discovery system that integrates LLM's instruction-following ability with statistical models to handle large, noisy datasets where LLM reasoning alone falls short.   Instruct-LF uses LLMs to propose fine-grained, goal-related properties from documents, estimates their presence across the dataset, and applies gradient-based optimization to uncover hidden factors, where each factor is represented by a cluster of co-occurring properties. We evaluate latent factors produced by Instruct-LF on movie recommendation, text-world navigation, and legal document categorization tasks. These interpretable representations improve downstream task performance by 5-52% than the best baselines and were preferred 1.8 times as often as the best alternative, on average, in human evaluation.",
    "categories": [
        "cs.CL"
    ],
    "created": "2025-04-27",
    "updated": "2025-04-29"
}