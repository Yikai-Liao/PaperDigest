{
    "title": "Replay to Remember: Retaining Domain Knowledge in Streaming Language Models",
    "authors": [
        "Sneh Pillai"
    ],
    "institution": [
        "University of Massachusetts Dartmouth"
    ],
    "problem_background": "大型语言模型（LLMs）在持续学习中面临灾难性遗忘的重大挑战，即当暴露于新数据时，先前习得的知识会迅速退化。尽管诸如重放缓冲区和低秩适应（LoRA）等技术已被提出，但鲜有研究探讨在严格的计算资源和数据流约束下的实时域适应。本文的工作起点是解决在资源受限的真实世界场景中，LLMs如何能够持续适应新知识流而不丢失先前领域知识。",
    "method": "* **核心思想：** 结合LoRA参数高效微调和最小重放机制，在流式学习环境中减轻LLMs的灾难性遗忘。\n* **如何实现：** 使用LoRA仅更新模型注意力层的低秩矩阵，以减少计算开销；同时，引入一个轻量级重放缓冲区，按比例重新引入先前见过的样本，以维持知识保留。\n* **主要步骤：** 数据以增量批次流式输入，模型在每个批次上进行LoRA微调，并周期性地应用重放缓冲区来强化先前知识。",
    "experiment": "* **数据集和设置：** 实验使用三个不同领域的流式数据集：医疗问答（MedQuAD）、遗传信息和法律信息。数据以小批次形式顺序输入，模拟实时域移位场景。模型在计算资源受限的硬件上运行，使用LoRA和最小重放机制，以反映真实部署环境。\n* **评估指标：** 采用困惑度（衡量预测不确定性）、语义相似度（使用余弦相似度量化语义漂移）和GPT-4基于人类评价的评分（1-10分，评估答案的相关性、完整性和流畅性）来量化适应、遗忘和恢复。\n* **结果：** 结果显示灾难性遗忘确实发生，但最小重放机制显著稳定了性能并部分恢复了知识。例如，在遗传领域，困惑度从2906.99上升到超过32万，但重放后有所下降；法律领域显示更稳定，语义相似度和GPT评分变化较小。实验结果与预期一致，验证了方法的有效性，同时突出了域间差异，如遗传领域遗忘更严重。",
    "one_sentence_summary": "本文通过结合LoRA和轻量级重放机制的方法，在流式学习条件下帮助大型语言模型减轻灾难性遗忘，同时实现了实时域适应。",
    "slug": "replay-to-remember-retaining-domain-knowledge",
    "keywords": [
        "Continual Learning",
        "LoRA",
        "Replay Buffer",
        "Language Models",
        "Real-Time Adaptation",
        "Catastrophic Forgetting"
    ],
    "further_thoughts": "这项研究强调了重放机制在持续学习中的重要性，启发我们探索更先进的策略，如基于重要性的样本选择或多域适配器融合，以进一步减少遗忘；此外，结合其他领域如计算机视觉的增量学习或强化学习的经验回放，可能带来交叉启发，并考虑元学习来改善初始适应能力。",
    "model": "grok-3-mini-latest",
    "temperature": 0.5,
    "top_p": 0.7,
    "lang": "zh",
    "id": "2504.17780",
    "preference": "unknown",
    "summary_time": "2025-05-04T08:30:18.900033+00:00",
    "score": 0.6513709448813092,
    "abstract": "Continual learning in large language models (LLMs) typically encounters the critical challenge of catastrophic forgetting, where previously acquired knowledge deteriorates upon exposure to new data. While techniques like replay buffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have been proposed, few studies investigate real-time domain adaptation under strict computational and data-stream constraints. In this paper, we demonstrate a lightweight method combining LoRA and a minimal replay mechanism in a realistic streaming setting across three diverse knowledge domains: medical question answering, genetics, and law. Using perplexity, semantic similarity, and GPT-based human-like evaluation metrics, we quantify the model's adaptation, forgetting, and recovery over time. Our experiments reveal that while catastrophic forgetting naturally occurs, even minimal replay significantly stabilizes and partially restores domain-specific knowledge. This study contributes practical insights for deploying adaptable LLMs in resource-constrained, real-world scenarios.",
    "categories": [
        "cs.LG"
    ],
    "created": "2025-04-24",
    "updated": "2025-04-25"
}