{
    "title": "Towards Reasoning Ability of Small Language Models",
    "authors": [
        "Gaurav Srivastava",
        "Shuxiang Cao",
        "Xuan Wang"
    ],
    "institution": [
        "Virginia Tech",
        "University of Oxford",
        "NVIDIA Corporation"
    ],
    "problem_background": "长期以来，推理能力被视为大型语言模型（LLMs）的涌现属性，仅在模型规模达到约100B参数时出现。然而，最近的研究挑战了这一假设，表明小型语言模型（SLMs）也能实现具有竞争力的推理性能。SLMs因其高效性和易部署性而日益受欢迎，但缺乏对不同SLMs（包括从头训练或通过量化、剪枝和蒸馏从LLMs派生而来的模型）的系统性研究，这引发了一个关键问题：SLMs能否实现与LLMs相当的推理能力？本研究旨在通过系统调查和基准测试来填补这一空白。",
    "method": "*   **核心思想：** 系统评估SLMs的推理能力，包括从头训练的模型及其压缩变体（如量化、剪枝和蒸馏版本）。\n*   **实现方式：** 选择了72个SLMs，涵盖六大模型家族（如Llama和Qwen），并在14个推理基准上进行评估。评估方法包括比较四种评估框架（解析-based方法、LLM-as-a-Judge和人工评估），并使用GPT-4o作为主要评估器。同时，分析了提示策略的影响、模型在对抗条件下的鲁棒性和中间推理步骤。\n*   **主要步骤：** （1）建立可靠的评估指标；（2）在GSM8K、ARC、CommonsenseQA等数据集上测试模型；（3）评估量化、剪枝和蒸馏等压缩技术的影响；（4）重复实验三次以确保鲁棒性。",
    "experiment": "*   **数据集和设置：** 使用了GSM8K、MATH、ARC-E/C、CommonsenseQA、HellaSwag、MathQA、OpenBookQA等14个基准数据集，涵盖数学推理、科学推理和常识推理。实验包括不同提示策略（直接I/O、CoT、多shot等）、压缩技术（量化、剪枝、蒸馏）和鲁棒性测试（如对抗扰动）。所有实验重复三次，报告均值和标准差，以确保可靠性。\n*   **结果：** 结果显示，SLMs（如Qwen2.5家族）在某些任务中可与LLMs（如GPT-4-Turbo）媲美，量化对性能影响最小，而剪枝显著降低性能。实验设置全面合理，突出了训练数据和优化策略的重要性。结果与预期一致，即推理能力不仅依赖规模，还受结构化训练和压缩技术影响。\n*   **是否符合预期：** 是的，实验证实了SLMs可以通过优化实现强推理能力，但剪枝等方法可能导致性能下降，这与作者的假设相符。",
    "one_sentence_summary": "本文通过系统基准测试72个SLMs，证明小型语言模型可以通过结构化训练和压缩技术实现与大型模型相当的推理能力，从而挑战了规模依赖的传统观点。",
    "slug": "reasoning-ability-small-language-models",
    "keywords": [
        "Small Language Models",
        "Reasoning",
        "Benchmarking",
        "Compression",
        "Prompting"
    ],
    "further_thoughts": "这项研究强调了SLMs在推理任务中的潜力，并提示未来工作应探索更先进的压缩策略和训练方法，以提升模型的泛化能力；同时，与DeepSeek-R1的蒸馏方法相比，本文的结果表明，SLMs的推理能力可能更依赖于高质量的数据和优化，而非单纯的规模扩展，这为资源受限环境下的AI部署提供了新思路，并可能与其他领域如计算机视觉中的轻量模型设计相结合，以实现更高效的跨模态推理系统。",
    "model": "grok-3-mini-latest",
    "temperature": 0.5,
    "top_p": 0.7,
    "lang": "zh",
    "id": "2502.11569",
    "preference": "unknown",
    "summary_time": "2025-05-04T08:26:21.867008+00:00",
    "score": 0.8653303321373326,
    "abstract": "Reasoning has long been viewed as an emergent property of large language models (LLMs), appearing at or above a certain scale ($\\sim$100B parameters). However, recent studies challenge this assumption, showing that small language models (SLMs) can also achieve competitive reasoning performance. SLMs are increasingly favored for their efficiency and deployability. However, there is a lack of systematic study on the reasoning abilities of diverse SLMs, including those trained from scratch or derived from LLMs through quantization, pruning, and distillation. This raises a critical question: Can SLMs achieve reasoning abilities comparable to LLMs? In this work, we systematically survey, benchmark, and analyze 72 SLMs from six model families across 14 reasoning benchmarks. For reliable evaluation, we examine four evaluation methods and compare four LLM judges against human evaluations on 800 data points. We repeat all experiments three times to ensure a robust performance assessment. Additionally, we analyze the impact of different prompting strategies in small models. Beyond accuracy, we also evaluate model robustness under adversarial conditions and intermediate reasoning steps. Our findings challenge the assumption that scaling is the only way to achieve strong reasoning. Instead, we foresee a future where SLMs with strong reasoning capabilities can be developed through structured training or post-training compression. They can serve as efficient alternatives to LLMs for reasoning-intensive tasks.",
    "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
    ],
    "created": "2025-04-23",
    "updated": "2025-04-25"
}