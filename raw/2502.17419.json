{
    "title": "From System 1 to System 2: A Survey of Reasoning Large Language Models",
    "authors": [
        "Zhong-Zhi Li",
        "Duzhen Zhang",
        "Ming-Liang Zhang",
        "Jiaxin Zhang",
        "Zengyan Liu",
        "Yuxuan Yao",
        "Haotian Xu",
        "Junhao Zheng",
        "Pei-Jie Wang",
        "Xiuyi Chen",
        "Yingying Zhang",
        "Fei Yin",
        "Jiahua Dong",
        "Zhiwei Li",
        "Bao-Long Bi",
        "Ling-Rui Mei",
        "Junfeng Fang",
        "Zhijiang Guo",
        "Le Song",
        "Cheng-Lin Liu"
    ],
    "institution": [
        "University of Strathclyde, Glasgow, UK",
        "Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE",
        "Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "Alibaba Group, Beijing, China",
        "City University of Hong Kong, Hong Kong, China",
        "Hong Kong University of Science and Technology (Guangzhou), China",
        "Xiaohongshu Inc, Beijing, China",
        "East China Normal University, Shanghai, China",
        "Nanyang Technological University, Singapore",
        "South China University of Technology, Guangzhou, China"
    ],
    "problem_background": "本文探讨了从快速、直观的System 1思维向缓慢、深思熟虑的System 2思维的转变，以实现人类级别的智能。双系统理论指出，人类认知包括System 1（快速、自动、直观的决策）和System 2（缓慢、分析、深思熟虑的推理）。基础大型语言模型（LLMs）在快速决策方面表现出色，但缺乏复杂推理的深度，无法进行类似于System 2的逐步分析，从而在涉及逻辑推理、多步问题解决或细微理解的场景中表现不足。推理LLMs（如OpenAI的o1/o3和DeepSeek的R1）通过模拟System 2思维，实现了专家级性能，特别是在数学、编码和多模态推理任务中，展示了类人认知能力。本文的关键问题是如何将基础LLMs与早期System 2技术（如符号逻辑、MCTS和RL）相结合，构建出更强大的推理模型，以解决复杂任务中的偏差和错误。",
    "method": "本文的方法是通过调查和分析构建推理LLMs的核心思想和步骤。首先，概述了基础LLMs的发展和早期System 2技术的进展，包括符号逻辑系统、Monte Carlo树搜索（MCTS）和强化学习（RL），强调这些技术的结合为推理LLMs铺平了道路。具体实现包括：分析推理LLMs的特征，从输出行为（如探索与规划、验证与检查结构、推理长度）和服务训练动态（如数据效率、稀疏训练、参数特性）两个角度进行比较；识别核心方法，包括结构搜索（使用MCTS模拟推理路径）、奖励建模（ORM和PRM提供反馈）、自我改进（通过自我训练和强化学习）、宏观行动（分层规划和行动框架）、以及强化微调（RFT通过RL优化推理）。这些方法通过在推理过程中动态调整和优化，确保模型在不牺牲性能的前提下实现高效、准确的推理。",
    "experiment": "实验部分评估了推理LLMs在各种基准上的性能，使用的数据集包括数学（如GSM8K、MATH、AIME 2024）、代码（如Codeforces、SWE-bench）、科学（如GPQA、MMLU-Pro）和多模态任务（如MMMU、MathVista）的基准。实验设置全面，比较了推理LLMs（如DeepSeek-R1、OpenAI o1/o3）与基础LLMs（如DeepSeek-V3、GPT-4o）的性能，采用指标如Pass@1、准确率和Percentile。结果显示，推理LLMs在保持教师模型准确率的同时显著提升了推理能力，例如DeepSeek-R1在MATH-500上的Pass@1得分高达97.3%，优于基础模型；MCTS和RL方法在实验中证明了有效性，但也暴露了问题，如计算开销大和奖励机制依赖性强。这些结果与预期一致，突出了推理LLMs的优势，但也指出了基准饱和、数据泄漏和泛化挑战，需要更全面的评估框架。",
    "one_sentence_summary": "本文综述了从基础LLMs向推理LLMs的演进，通过整合System 2技术提升AI的逐步推理能力，并在基准测试中展示了显著性能改进。",
    "slug": "from-system-1-to-system-2-survey-reasoning-llms",
    "keywords": [
        "Large Language Models",
        "Reasoning",
        "System 2",
        "Monte Carlo Tree Search",
        "Reinforcement Learning"
    ],
    "further_thoughts": "本文强调了符号逻辑和MCTS与LLMs的结合，可能启发在其他领域如机器人规划或金融决策中开发混合AI系统，以提高可解释性和推理能力。同时，奖励建模方法可能与博弈论的多代理系统相关联，探索如何在动态环境中优化决策策略；此外，推理LLMs的自我改进机制可扩展到跨语言或多模态任务，解决低资源语言的推理挑战，并促进AI在科学发现中的应用，如通过强化学习实现更安全的模型演化。",
    "model": "grok-3-mini-latest",
    "temperature": 0.5,
    "top_p": 0.7,
    "lang": "zh",
    "id": "2502.17419",
    "preference": "unknown",
    "summary_time": "2025-05-04T08:26:52.503703+00:00",
    "score": 0.7503547032801408,
    "abstract": "Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 thinking. Recently, reasoning LLMs like OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level performance in fields such as mathematics and coding, closely mimicking the deliberate reasoning of System 2 and showcasing human-like cognitive abilities. This survey begins with a brief overview of the progress in foundational LLMs and the early development of System 2 technologies, exploring how their combination has paved the way for reasoning LLMs. Next, we discuss how to construct reasoning LLMs, analyzing their features, the core methods enabling advanced reasoning, and the evolution of various reasoning LLMs. Additionally, we provide an overview of reasoning benchmarks, offering an in-depth comparison of the performance of representative reasoning LLMs. Finally, we explore promising directions for advancing reasoning LLMs and maintain a real-time \\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub Repository} to track the latest developments. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this rapidly evolving field.",
    "categories": [
        "cs.AI"
    ],
    "created": "2025-04-25",
    "updated": "2025-04-28"
}